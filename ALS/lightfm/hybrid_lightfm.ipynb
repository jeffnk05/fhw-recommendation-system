{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6681bfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ziaja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightfm in c:\\users\\ziaja\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.17)\n",
      "Requirement already satisfied: numpy in c:\\users\\ziaja\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightfm) (2.2.5)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\ziaja\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightfm) (1.15.3)\n",
      "Requirement already satisfied: requests in c:\\users\\ziaja\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightfm) (2.32.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ziaja\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightfm) (1.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ziaja\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->lightfm) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ziaja\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->lightfm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ziaja\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->lightfm) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ziaja\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->lightfm) (2025.4.26)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ziaja\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->lightfm) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ziaja\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->lightfm) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from lightfm.evaluation import precision_at_k, auc_score\n",
    "from scipy import sparse\n",
    "import gc  # For garbage collection\n",
    "import os\n",
    "%pip install lightfm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c0a486",
   "metadata": {},
   "source": [
    "# 2. Load & Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5f10637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books dataset shape: (10000, 23)\n",
      "Ratings dataset shape: (5976479, 3)\n",
      "\n",
      "Books sample:\n",
      "   book_id  goodreads_book_id  best_book_id  work_id  books_count       isbn  \\\n",
      "0        1            2767052       2767052  2792775          272  439023483   \n",
      "1        2                  3             3  4640799          491  439554934   \n",
      "2        3              41865         41865  3212258          226  316015849   \n",
      "3        4               2657          2657  3275794          487   61120081   \n",
      "4        5               4671          4671   245494         1356  743273567   \n",
      "\n",
      "         isbn13                      authors  original_publication_year  \\\n",
      "0  9.780439e+12              Suzanne Collins                     2008.0   \n",
      "1  9.780440e+12  J.K. Rowling, Mary GrandPr√©                     1997.0   \n",
      "2  9.780316e+12              Stephenie Meyer                     2005.0   \n",
      "3  9.780061e+12                   Harper Lee                     1960.0   \n",
      "4  9.780743e+12          F. Scott Fitzgerald                     1925.0   \n",
      "\n",
      "                             original_title  ... ratings_count  \\\n",
      "0                          The Hunger Games  ...       4780653   \n",
      "1  Harry Potter and the Philosopher's Stone  ...       4602479   \n",
      "2                                  Twilight  ...       3866839   \n",
      "3                     To Kill a Mockingbird  ...       3198671   \n",
      "4                          The Great Gatsby  ...       2683664   \n",
      "\n",
      "  work_ratings_count  work_text_reviews_count  ratings_1  ratings_2  \\\n",
      "0            4942365                   155254      66715     127936   \n",
      "1            4800065                    75867      75504     101676   \n",
      "2            3916824                    95009     456191     436802   \n",
      "3            3340896                    72586      60427     117415   \n",
      "4            2773745                    51992      86236     197621   \n",
      "\n",
      "   ratings_3  ratings_4  ratings_5  \\\n",
      "0     560092    1481305    2706317   \n",
      "1     455024    1156318    3011543   \n",
      "2     793319     875073    1355439   \n",
      "3     446835    1001952    1714267   \n",
      "4     606158     936012     947718   \n",
      "\n",
      "                                           image_url  \\\n",
      "0  https://images.gr-assets.com/books/1447303603m...   \n",
      "1  https://images.gr-assets.com/books/1474154022m...   \n",
      "2  https://images.gr-assets.com/books/1361039443m...   \n",
      "3  https://images.gr-assets.com/books/1361975680m...   \n",
      "4  https://images.gr-assets.com/books/1490528560m...   \n",
      "\n",
      "                                     small_image_url  \n",
      "0  https://images.gr-assets.com/books/1447303603s...  \n",
      "1  https://images.gr-assets.com/books/1474154022s...  \n",
      "2  https://images.gr-assets.com/books/1361039443s...  \n",
      "3  https://images.gr-assets.com/books/1361975680s...  \n",
      "4  https://images.gr-assets.com/books/1490528560s...  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "Ratings sample:\n",
      "   user_id  book_id  rating\n",
      "0        1      258       5\n",
      "1        2     4081       4\n",
      "2        2      260       5\n",
      "3        2     9296       5\n",
      "4        2     2318       3\n",
      "\n",
      "Missing values in books dataset:\n",
      "book_id                         0\n",
      "goodreads_book_id               0\n",
      "best_book_id                    0\n",
      "work_id                         0\n",
      "books_count                     0\n",
      "isbn                          700\n",
      "isbn13                        585\n",
      "authors                         0\n",
      "original_publication_year      21\n",
      "original_title                585\n",
      "title                           0\n",
      "language_code                1084\n",
      "average_rating                  0\n",
      "ratings_count                   0\n",
      "work_ratings_count              0\n",
      "work_text_reviews_count         0\n",
      "ratings_1                       0\n",
      "ratings_2                       0\n",
      "ratings_3                       0\n",
      "ratings_4                       0\n",
      "ratings_5                       0\n",
      "image_url                       0\n",
      "small_image_url                 0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in ratings dataset:\n",
      "user_id    0\n",
      "book_id    0\n",
      "rating     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "books = pd.read_csv('../data/books.csv')\n",
    "ratings = pd.read_csv('../data/ratings.csv')\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "print(\"Books dataset shape:\", books.shape)\n",
    "print(\"Ratings dataset shape:\", ratings.shape)\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nBooks sample:\")\n",
    "print(books.head())\n",
    "\n",
    "print(\"\\nRatings sample:\")\n",
    "print(ratings.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in books dataset:\")\n",
    "print(books.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in ratings dataset:\")\n",
    "print(ratings.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6952012",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2921b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries in books dataset: 0\n",
      "Duplicate entries in ratings dataset: 0\n",
      "\n",
      "Rating statistics:\n",
      "count    5.976479e+06\n",
      "mean     3.919866e+00\n",
      "std      9.910868e-01\n",
      "min      1.000000e+00\n",
      "25%      3.000000e+00\n",
      "50%      4.000000e+00\n",
      "75%      5.000000e+00\n",
      "max      5.000000e+00\n",
      "Name: rating, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ratings per user statistics:\n",
      "count    53424.000000\n",
      "mean       111.868804\n",
      "std         26.071224\n",
      "min         19.000000\n",
      "25%         96.000000\n",
      "50%        111.000000\n",
      "75%        128.000000\n",
      "max        200.000000\n",
      "dtype: float64\n",
      "\n",
      "Ratings per book statistics:\n",
      "count    10000.000000\n",
      "mean       597.647900\n",
      "std       1267.289788\n",
      "min          8.000000\n",
      "25%        155.000000\n",
      "50%        248.000000\n",
      "75%        503.000000\n",
      "max      22806.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate entries\n",
    "print(\"Duplicate entries in books dataset:\", books.duplicated().sum())\n",
    "print(\"Duplicate entries in ratings dataset:\", ratings.duplicated().sum())\n",
    "\n",
    "# Remove duplicates if any\n",
    "books = books.drop_duplicates()\n",
    "ratings = ratings.drop_duplicates()\n",
    "\n",
    "# Basic statistics of ratings\n",
    "print(\"\\nRating statistics:\")\n",
    "print(ratings['rating'].describe())\n",
    "\n",
    "# Distribution of ratings\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='rating', data=ratings)\n",
    "plt.title('Distribution of Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Number of ratings per user\n",
    "user_ratings_count = ratings.groupby('user_id').size()\n",
    "print(\"\\nRatings per user statistics:\")\n",
    "print(user_ratings_count.describe())\n",
    "\n",
    "# Number of ratings per book\n",
    "book_ratings_count = ratings.groupby('book_id').size()\n",
    "print(\"\\nRatings per book statistics:\")\n",
    "print(book_ratings_count.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237433f1",
   "metadata": {},
   "source": [
    "# 4. Feature Engineering for Content-Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f5274f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed book features shape: (10000, 4770)\n"
     ]
    }
   ],
   "source": [
    "# Select relevant features from books dataset and create a copy to avoid warnings\n",
    "book_features = books[['book_id', 'authors', 'original_publication_year', \n",
    "                       'language_code', 'average_rating']].copy()\n",
    "\n",
    "# Handle missing values\n",
    "book_features.loc[:, 'original_publication_year'] = book_features['original_publication_year'].fillna(0)\n",
    "\n",
    "# Convert publication year to decade for better generalization\n",
    "book_features.loc[:, 'decade'] = (book_features['original_publication_year'] // 10) * 10\n",
    "book_features.loc[:, 'decade'] = book_features['decade'].astype(int)\n",
    "\n",
    "# Extract primary language\n",
    "book_features.loc[:, 'primary_language'] = book_features['language_code'].str.split('-').str[0]\n",
    "\n",
    "# Create dummy variables for categorical features\n",
    "authors_dummies = pd.get_dummies(book_features['authors'], prefix='author')\n",
    "language_dummies = pd.get_dummies(book_features['primary_language'], prefix='lang')\n",
    "decade_dummies = pd.get_dummies(book_features['decade'], prefix='decade')\n",
    "\n",
    "# Combine all features\n",
    "book_features_processed = pd.concat([\n",
    "    book_features[['book_id']], \n",
    "    authors_dummies, \n",
    "    language_dummies, \n",
    "    decade_dummies\n",
    "], axis=1)\n",
    "\n",
    "print(\"Processed book features shape:\", book_features_processed.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98103323",
   "metadata": {},
   "source": [
    "# 5. Prepare Data for LightFM\n",
    "Dauer: 17m 35s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebc4d40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing book features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[decade_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[lang_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[lang_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[lang_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[lang_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[lang_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[lang_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[lang_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[lang_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[lang_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[lang_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[lang_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[lang_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[lang_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[lang_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[lang_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[lang_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[lang_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[lang_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[lang_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[lang_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[lang_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[lang_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[lang_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[lang_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[lang_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[bin_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[bin_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[bin_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[bin_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[pop_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[pop_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[pop_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[pop_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[pop_name] = 0\n",
      "C:\\Users\\ziaja\\AppData\\Local\\Temp\\ipykernel_20180\\168101533.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[pop_name] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 412 features for 10000 books\n",
      "Creating LightFM dataset...\n",
      "Building interaction matrices...\n",
      "Processing interactions batch 1/60\n",
      "Processing interactions batch 2/60\n",
      "Processing interactions batch 3/60\n",
      "Processing interactions batch 4/60\n",
      "Processing interactions batch 5/60\n",
      "Processing interactions batch 6/60\n",
      "Processing interactions batch 7/60\n",
      "Processing interactions batch 8/60\n",
      "Processing interactions batch 9/60\n",
      "Processing interactions batch 10/60\n",
      "Processing interactions batch 11/60\n",
      "Processing interactions batch 12/60\n",
      "Processing interactions batch 13/60\n",
      "Processing interactions batch 14/60\n",
      "Processing interactions batch 15/60\n",
      "Processing interactions batch 16/60\n",
      "Processing interactions batch 17/60\n",
      "Processing interactions batch 18/60\n",
      "Processing interactions batch 19/60\n",
      "Processing interactions batch 20/60\n",
      "Processing interactions batch 21/60\n",
      "Processing interactions batch 22/60\n",
      "Processing interactions batch 23/60\n",
      "Processing interactions batch 24/60\n",
      "Processing interactions batch 25/60\n",
      "Processing interactions batch 26/60\n",
      "Processing interactions batch 27/60\n",
      "Processing interactions batch 28/60\n",
      "Processing interactions batch 29/60\n",
      "Processing interactions batch 30/60\n",
      "Processing interactions batch 31/60\n",
      "Processing interactions batch 32/60\n",
      "Processing interactions batch 33/60\n",
      "Processing interactions batch 34/60\n",
      "Processing interactions batch 35/60\n",
      "Processing interactions batch 36/60\n",
      "Processing interactions batch 37/60\n",
      "Processing interactions batch 38/60\n",
      "Processing interactions batch 39/60\n",
      "Processing interactions batch 40/60\n",
      "Processing interactions batch 41/60\n",
      "Processing interactions batch 42/60\n",
      "Processing interactions batch 43/60\n",
      "Processing interactions batch 44/60\n",
      "Processing interactions batch 45/60\n",
      "Processing interactions batch 46/60\n",
      "Processing interactions batch 47/60\n",
      "Processing interactions batch 48/60\n",
      "Processing interactions batch 49/60\n",
      "Processing interactions batch 50/60\n",
      "Processing interactions batch 51/60\n",
      "Processing interactions batch 52/60\n",
      "Processing interactions batch 53/60\n",
      "Processing interactions batch 54/60\n",
      "Processing interactions batch 55/60\n",
      "Processing interactions batch 56/60\n",
      "Processing interactions batch 57/60\n",
      "Processing interactions batch 58/60\n",
      "Processing interactions batch 59/60\n",
      "Processing interactions batch 60/60\n",
      "Building item feature matrices...\n",
      "Interactions matrix shape: (3205440, 10000)\n",
      "Item features matrix shape: (10000, 10412)\n"
     ]
    }
   ],
   "source": [
    "# Memory optimization\n",
    "gc.collect()\n",
    "\n",
    "# First, let's process the books data to extract features\n",
    "def process_book_features(books_df):\n",
    "    \"\"\"Extract and process features from the books dataset\"\"\"\n",
    "    print(\"Processing book features...\")\n",
    "    \n",
    "    # Create features from available columns\n",
    "    features = pd.DataFrame({'book_id': books_df['book_id']})\n",
    "    \n",
    "    # Publication year as decade features\n",
    "    years = books_df['original_publication_year'].dropna()\n",
    "    min_year = int(years.min()) if not years.empty else 1900\n",
    "    max_year = int(years.max()) if not years.empty else 2020\n",
    "    decades = list(range(int(min_year/10)*10, int(max_year/10+1)*10, 10))\n",
    "    \n",
    "    for decade in decades:\n",
    "        decade_name = f\"decade_{decade}s\"\n",
    "        features[decade_name] = 0\n",
    "        mask = (books_df['original_publication_year'] >= decade) & (books_df['original_publication_year'] < decade + 10)\n",
    "        features.loc[mask.index[mask], decade_name] = 1\n",
    "    \n",
    "    # Language features\n",
    "    languages = books_df['language_code'].dropna().unique()\n",
    "    for lang in languages:\n",
    "        lang_name = f\"lang_{lang}\"\n",
    "        features[lang_name] = 0\n",
    "        features.loc[books_df[books_df['language_code'] == lang].index, lang_name] = 1\n",
    "    \n",
    "    # Rating level features (based on average rating)\n",
    "    rating_bins = [0, 2, 3, 4, 5]\n",
    "    rating_labels = ['low_rated', 'medium_rated', 'high_rated', 'top_rated']\n",
    "    \n",
    "    for i in range(len(rating_bins)-1):\n",
    "        bin_name = rating_labels[i]\n",
    "        features[bin_name] = 0\n",
    "        mask = (books_df['average_rating'] >= rating_bins[i]) & (books_df['average_rating'] < rating_bins[i+1])\n",
    "        features.loc[mask.index[mask], bin_name] = 1\n",
    "    \n",
    "    # Popularity features (based on ratings_count)\n",
    "    ratings_count = books_df['ratings_count']\n",
    "    percentiles = [0, 25, 50, 75, 90, 95, 99]\n",
    "    thresholds = [ratings_count.quantile(p/100) for p in percentiles]\n",
    "    popularity_labels = ['very_niche', 'niche', 'medium_popular', 'popular', 'very_popular', 'blockbuster']\n",
    "    \n",
    "    for i in range(len(thresholds)-1):\n",
    "        pop_name = popularity_labels[i]\n",
    "        features[pop_name] = 0\n",
    "        mask = (books_df['ratings_count'] >= thresholds[i]) & (books_df['ratings_count'] < thresholds[i+1])\n",
    "        features.loc[mask.index[mask], pop_name] = 1\n",
    "    \n",
    "    # Remove any rows with NaN values to avoid issues\n",
    "    features = features.fillna(0)\n",
    "    \n",
    "    print(f\"Created {features.shape[1]-1} features for {features.shape[0]} books\")\n",
    "    return features\n",
    "\n",
    "# Process book features\n",
    "book_features_processed = process_book_features(books)\n",
    "\n",
    "# Create a LightFM dataset\n",
    "print(\"Creating LightFM dataset...\")\n",
    "dataset = Dataset()\n",
    "\n",
    "# Fit the dataset with user and item IDs\n",
    "dataset.fit(\n",
    "    users=ratings['user_id'].unique(),\n",
    "    items=ratings['book_id'].unique(),\n",
    "    item_features=book_features_processed.columns[1:].tolist()  # Exclude book_id column\n",
    ")\n",
    "\n",
    "# Build interaction matrices in batches to save memory\n",
    "print(\"Building interaction matrices...\")\n",
    "batch_size = 100000  # Adjust this based on your available memory\n",
    "interactions_list = []\n",
    "\n",
    "for i in range(0, len(ratings), batch_size):\n",
    "    print(f\"Processing interactions batch {i//batch_size + 1}/{(len(ratings) + batch_size - 1)//batch_size}\")\n",
    "    batch = ratings.iloc[i:i+batch_size]\n",
    "    interactions_data = list(zip(batch['user_id'], batch['book_id'], batch['rating']))\n",
    "    batch_interactions, _ = dataset.build_interactions(interactions_data)\n",
    "    interactions_list.append(batch_interactions)\n",
    "    \n",
    "    # Free memory\n",
    "    del batch\n",
    "    gc.collect()\n",
    "\n",
    "# Combine all interaction matrices\n",
    "interactions = sparse.vstack(interactions_list) if len(interactions_list) > 1 else interactions_list[0]\n",
    "del interactions_list\n",
    "gc.collect()\n",
    "\n",
    "# Build item features matrix\n",
    "print(\"Building item feature matrices...\")\n",
    "item_features_data = []\n",
    "batch_size = 1000  # Process books in batches\n",
    "\n",
    "for i in range(0, len(book_features_processed), batch_size):\n",
    "    batch = book_features_processed.iloc[i:i+batch_size]\n",
    "    for _, row in batch.iterrows():\n",
    "        book_id = row['book_id']\n",
    "        # Get features that are set to 1 (excluding book_id)\n",
    "        active_features = row.index[1:][row.iloc[1:] == 1].tolist()\n",
    "        if active_features:\n",
    "            item_features_data.append((book_id, {feature: 1.0 for feature in active_features}))\n",
    "    \n",
    "    # Free memory\n",
    "    del batch\n",
    "    gc.collect()\n",
    "\n",
    "# Build the features matrix\n",
    "item_features = dataset.build_item_features(item_features_data)\n",
    "del item_features_data\n",
    "gc.collect()\n",
    "\n",
    "print(\"Interactions matrix shape:\", interactions.shape)\n",
    "print(\"Item features matrix shape:\", item_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d03e09",
   "metadata": {},
   "source": [
    "# 6. Split Data into Training and Test Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fb9ec62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into training and test sets...\n",
      "Train set has 4781184 interactions (80.0% of total)\n",
      "Test set has 1195295 interactions (20.0% of total)\n",
      "Train interactions shape: (3205440, 10000)\n",
      "Test interactions shape: (3205440, 10000)\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(interactions, test_percentage=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split interactions matrix into training and test sets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    interactions : scipy.sparse matrix\n",
    "        The interaction matrix to split\n",
    "    test_percentage : float\n",
    "        Fraction of interactions to place in the test set\n",
    "    random_state : int\n",
    "        Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    train : scipy.sparse.csr_matrix\n",
    "        Training set interactions\n",
    "    test : scipy.sparse.csr_matrix\n",
    "        Test set interactions\n",
    "    \"\"\"\n",
    "    print(\"Splitting data into training and test sets...\")\n",
    "    \n",
    "    # Convert to COO format for easier manipulation\n",
    "    interactions = interactions.tocoo()\n",
    "    num_interactions = interactions.nnz\n",
    "    test_size = int(test_percentage * num_interactions)\n",
    "    \n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Shuffle indices\n",
    "    indices = np.arange(num_interactions)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    # Split indices\n",
    "    test_indices = indices[:test_size]\n",
    "    train_indices = indices[test_size:]\n",
    "\n",
    "    # Create train set\n",
    "    train = sparse.coo_matrix(\n",
    "        (interactions.data[train_indices],\n",
    "         (interactions.row[train_indices], interactions.col[train_indices])),\n",
    "        shape=interactions.shape\n",
    "    ).tocsr()\n",
    "    \n",
    "    # Create test set\n",
    "    test = sparse.coo_matrix(\n",
    "        (interactions.data[test_indices],\n",
    "         (interactions.row[test_indices], interactions.col[test_indices])),\n",
    "        shape=interactions.shape\n",
    "    ).tocsr()\n",
    "    \n",
    "    # Free memory\n",
    "    del indices, test_indices, train_indices\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"Train set has {train.nnz} interactions ({train.nnz / interactions.nnz:.1%} of total)\")\n",
    "    print(f\"Test set has {test.nnz} interactions ({test.nnz / interactions.nnz:.1%} of total)\")\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "# Split the data\n",
    "train_interactions, test_interactions = train_test_split(interactions, test_percentage=0.2)\n",
    "\n",
    "print(\"Train interactions shape:\", train_interactions.shape)\n",
    "print(\"Test interactions shape:\", test_interactions.shape)\n",
    "\n",
    "# Save user and item mappings for later use\n",
    "user_id_map, _, item_id_map, _ = dataset.mapping()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1765be80",
   "metadata": {},
   "source": [
    "# 7. Train the LightFM Model\n",
    "kernel is still crashing during the training phase (Step 7). This is likely due to memory issues with the large dataset. a more optimized version of Step 7 that uses less memory and has better error handling is created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff71df32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (1000, 2000), 20000 interactions\n",
      "Testing data: (1000, 2000), 4000 interactions\n",
      "Training LightFM model with 20 components using bpr loss...\n",
      "Starting main training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully!\n",
      "Evaluating model performance...\n",
      "Train precision at k=10: 0.0109\n",
      "Test precision at k=10: 0.0031\n",
      "Train AUC: 0.5226\n",
      "Test AUC: 0.4973\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k, auc_score\n",
    "\n",
    "# Step 1: Create or load your interaction data\n",
    "# If you don't have the data yet, you need to load or create it first\n",
    "# Example of creating sparse interaction matrices:\n",
    "def load_interaction_data():\n",
    "    # Replace this with your actual data loading code\n",
    "    # This is just a placeholder example\n",
    "    \n",
    "    # Number of users and items\n",
    "    n_users = 1000\n",
    "    n_items = 2000\n",
    "    \n",
    "    # Create random sparse matrices for demonstration\n",
    "    # In a real scenario, you would load your actual data\n",
    "    train_data = sp.random(n_users, n_items, density=0.01, format='coo', random_state=42)\n",
    "    train_data.data = np.ones(len(train_data.data))  # Convert to binary interactions\n",
    "    \n",
    "    test_data = sp.random(n_users, n_items, density=0.002, format='coo', random_state=43)\n",
    "    test_data.data = np.ones(len(test_data.data))  # Convert to binary interactions\n",
    "    \n",
    "    # Optional: Create item features (if you have them)\n",
    "    item_features = sp.identity(n_items, format='csr')  # One-hot encoded item features\n",
    "    \n",
    "    return train_data, test_data, item_features\n",
    "\n",
    "# Load the data\n",
    "train_interactions, test_interactions, item_features = load_interaction_data()\n",
    "\n",
    "# Step 2: Check the size and downsample if necessary\n",
    "print(f\"Training data: {train_interactions.shape}, {train_interactions.nnz} interactions\")\n",
    "print(f\"Testing data: {test_interactions.shape}, {test_interactions.nnz} interactions\")\n",
    "\n",
    "# Safe downsampling if data is too large\n",
    "if train_interactions.nnz > 5000000:  # If more than 5M interactions\n",
    "    print(\"Downsampling large training dataset...\")\n",
    "    # Create a mask for random selection\n",
    "    mask = np.random.random(train_interactions.nnz) < (5000000 / train_interactions.nnz)\n",
    "    \n",
    "    # Apply the mask to the COO matrix data\n",
    "    train_interactions_coo = train_interactions.tocoo()\n",
    "    rows = train_interactions_coo.row[mask]\n",
    "    cols = train_interactions_coo.col[mask]\n",
    "    data = train_interactions_coo.data[mask]\n",
    "    \n",
    "    # Create a new downsampled matrix\n",
    "    train_interactions = sp.coo_matrix(\n",
    "        (data, (rows, cols)), \n",
    "        shape=train_interactions.shape\n",
    "    ).tocsr()\n",
    "    \n",
    "    print(f\"Downsampled to {train_interactions.nnz} interactions\")\n",
    "\n",
    "# Step 3: Train the model\n",
    "print(\"Training LightFM model with 20 components using bpr loss...\")\n",
    "model = LightFM(no_components=20, \n",
    "                loss='bpr',  # 'bpr' or 'warp' are good choices\n",
    "                learning_rate=0.05, \n",
    "                random_state=42)\n",
    "\n",
    "try:\n",
    "    # Try training with all features\n",
    "    print(\"Starting main training...\")\n",
    "    model.fit(train_interactions, \n",
    "              item_features=item_features,\n",
    "              epochs=5, \n",
    "              num_threads=2,\n",
    "              verbose=True)\n",
    "    print(\"Training completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during training: {str(e)}\")\n",
    "    print(\"Trying fallback training without item features...\")\n",
    "    try:\n",
    "        # Fallback to simpler training if the first attempt fails\n",
    "        model = LightFM(no_components=10, loss='bpr', learning_rate=0.05)\n",
    "        model.fit(train_interactions, epochs=5, num_threads=1, verbose=True)\n",
    "        print(\"Fallback training completed successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fallback training also failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Step 4: Evaluate the model\n",
    "print(\"Evaluating model performance...\")\n",
    "try:\n",
    "    train_precision = precision_at_k(\n",
    "        model, \n",
    "        train_interactions, \n",
    "        item_features=item_features, \n",
    "        k=10\n",
    "    ).mean()\n",
    "\n",
    "    test_precision = precision_at_k(\n",
    "        model, \n",
    "        test_interactions, \n",
    "        item_features=item_features, \n",
    "        k=10\n",
    "    ).mean()\n",
    "\n",
    "    train_auc = auc_score(\n",
    "        model, \n",
    "        train_interactions, \n",
    "        item_features=item_features\n",
    "    ).mean()\n",
    "\n",
    "    test_auc = auc_score(\n",
    "        model, \n",
    "        test_interactions, \n",
    "        item_features=item_features\n",
    "    ).mean()\n",
    "\n",
    "    print(f\"Train precision at k=10: {train_precision:.4f}\")\n",
    "    print(f\"Test precision at k=10: {test_precision:.4f}\")\n",
    "    print(f\"Train AUC: {train_auc:.4f}\")\n",
    "    print(f\"Test AUC: {test_auc:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during evaluation: {str(e)}\")\n",
    "    \n",
    "    # Try evaluation without item features\n",
    "    try:\n",
    "        print(\"Trying evaluation without item features...\")\n",
    "        train_precision = precision_at_k(model, train_interactions, k=10).mean()\n",
    "        test_precision = precision_at_k(model, test_interactions, k=10).mean()\n",
    "        train_auc = auc_score(model, train_interactions).mean()\n",
    "        test_auc = auc_score(model, test_interactions).mean()\n",
    "        \n",
    "        print(f\"Train precision at k=10: {train_precision:.4f}\")\n",
    "        print(f\"Test precision at k=10: {test_precision:.4f}\")\n",
    "        print(f\"Train AUC: {train_auc:.4f}\")\n",
    "        print(f\"Test AUC: {test_auc:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Simplified evaluation also failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4892ac91",
   "metadata": {},
   "source": [
    "# 8. Evaluate the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7beb662b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train precision at k=10: 0.0109\n",
      "Test precision at k=10: 0.0031\n",
      "Train AUC: 0.5226\n",
      "Test AUC: 0.4973\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using precision at k and AUC\n",
    "train_precision = precision_at_k(\n",
    "    model, \n",
    "    train_interactions, \n",
    "    item_features=item_features, \n",
    "    k=10\n",
    ").mean()\n",
    "\n",
    "test_precision = precision_at_k(\n",
    "    model, \n",
    "    test_interactions, \n",
    "    item_features=item_features, \n",
    "    k=10\n",
    ").mean()\n",
    "\n",
    "train_auc = auc_score(\n",
    "    model, \n",
    "    train_interactions, \n",
    "    item_features=item_features\n",
    ").mean()\n",
    "\n",
    "test_auc = auc_score(\n",
    "    model, \n",
    "    test_interactions, \n",
    "    item_features=item_features\n",
    ").mean()\n",
    "\n",
    "print(f\"Train precision at k=10: {train_precision:.4f}\")\n",
    "print(f\"Test precision at k=10: {test_precision:.4f}\")\n",
    "print(f\"Train AUC: {train_auc:.4f}\")\n",
    "print(f\"Test AUC: {test_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84843fb8",
   "metadata": {},
   "source": [
    "# 9. Generate Recommendations for Users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "866e2e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_for_user(model, user_id, item_features, dataset, books_df, n=10):\n",
    "    \"\"\"\n",
    "    Get top N book recommendations for a specific user.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : LightFM model\n",
    "        Trained recommendation model\n",
    "    user_id : int or str\n",
    "        The external user ID to get recommendations for\n",
    "    item_features : scipy.sparse matrix\n",
    "        Item features matrix\n",
    "    dataset : LightFM Dataset\n",
    "        Dataset object containing ID mappings\n",
    "    books_df : pandas DataFrame\n",
    "        DataFrame containing book information\n",
    "    n : int\n",
    "        Number of recommendations to generate\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with book recommendations and their details\n",
    "    \"\"\"\n",
    "    # Get mappings\n",
    "    user_id_map, _, item_id_map, _ = dataset.mapping()\n",
    "    \n",
    "    # Convert external user ID to internal ID\n",
    "    if user_id not in user_id_map:\n",
    "        raise ValueError(f\"User ID {user_id} not found in the dataset\")\n",
    "    \n",
    "    user_idx = user_id_map[user_id]\n",
    "    \n",
    "    # Get scores for all items for this user\n",
    "    n_items = item_features.shape[0]\n",
    "    scores = model.predict(\n",
    "        user_ids=user_idx,\n",
    "        item_ids=np.arange(n_items),\n",
    "        item_features=item_features\n",
    "    )\n",
    "    \n",
    "    # Create mapping from internal to external item IDs\n",
    "    reverse_item_map = {idx: item_id for item_id, idx in item_id_map.items()}\n",
    "    \n",
    "    # Get top N item indices\n",
    "    top_items_idx = np.argsort(-scores)[:n]\n",
    "    \n",
    "    # Convert to original book IDs\n",
    "    top_book_ids = [reverse_item_map[idx] for idx in top_items_idx]\n",
    "    top_scores = scores[top_items_idx]\n",
    "    \n",
    "    # Get book details\n",
    "    recommendations = books_df[books_df['book_id'].isin(top_book_ids)]\n",
    "    \n",
    "    # Add prediction scores and sort by score\n",
    "    recommendations_with_scores = recommendations.copy()\n",
    "    recommendations_with_scores['score'] = 0.0\n",
    "    \n",
    "    for i, book_id in enumerate(top_book_ids):\n",
    "        idx = recommendations_with_scores.index[recommendations_with_scores['book_id'] == book_id]\n",
    "        if len(idx) > 0:\n",
    "            recommendations_with_scores.loc[idx[0], 'score'] = float(top_scores[i])\n",
    "    \n",
    "    # Sort by score\n",
    "    recommendations_with_scores = recommendations_with_scores.sort_values('score', ascending=False)\n",
    "    \n",
    "    return recommendations_with_scores\n",
    "\n",
    "\n",
    "def get_similar_books(model, book_id, item_features, dataset, books_df, n=10):\n",
    "    \"\"\"\n",
    "    Get similar books to a given book based on learned item embeddings.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : LightFM model\n",
    "        Trained recommendation model\n",
    "    book_id : int or str\n",
    "        The external book ID to find similar books for\n",
    "    item_features : scipy.sparse matrix\n",
    "        Item features matrix\n",
    "    dataset : LightFM Dataset\n",
    "        Dataset object containing ID mappings\n",
    "    books_df : pandas DataFrame\n",
    "        DataFrame containing book information\n",
    "    n : int\n",
    "        Number of similar books to retrieve\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with similar books and their details\n",
    "    \"\"\"\n",
    "    # Get mappings\n",
    "    _, _, item_id_map, _ = dataset.mapping()\n",
    "    \n",
    "    # Convert book_id to integer if it's a string\n",
    "    if isinstance(book_id, str) and book_id.isdigit():\n",
    "        book_id = int(book_id)\n",
    "    \n",
    "    # Convert external book ID to internal ID\n",
    "    if book_id not in item_id_map:\n",
    "        raise ValueError(f\"Book ID {book_id} not found in the dataset\")\n",
    "    \n",
    "    book_idx = item_id_map[book_id]\n",
    "    \n",
    "    # Get the embedding for this book\n",
    "    book_embedding = model.item_embeddings[book_idx]\n",
    "    \n",
    "    # Calculate similarity with all other books based on dot product\n",
    "    n_items = min(len(item_id_map), model.item_embeddings.shape[0])\n",
    "    similarities = np.zeros(n_items)\n",
    "    \n",
    "    for idx in range(n_items):\n",
    "        if idx != book_idx and idx < model.item_embeddings.shape[0]:\n",
    "        # Calculate similarity\n",
    "            similarities[idx] = np.dot(book_embedding, model.item_embeddings[idx]) / (\n",
    "                np.linalg.norm(book_embedding) * np.linalg.norm(model.item_embeddings[idx])\n",
    "            )\n",
    "    \n",
    "    # Create mapping from internal to external item IDs\n",
    "    reverse_item_map = {idx: item_id for item_id, idx in item_id_map.items()}\n",
    "    \n",
    "    # Get top N similar items (excluding the query book itself)\n",
    "    similar_items_idx = np.argsort(-similarities)[:n+1]\n",
    "    similar_items_idx = [idx for idx in similar_items_idx if idx != book_idx][:n]\n",
    "    \n",
    "    # Convert to original book IDs\n",
    "    similar_book_ids = [reverse_item_map[idx] for idx in similar_items_idx]\n",
    "    similarity_scores = similarities[similar_items_idx]\n",
    "    \n",
    "    # Get book details\n",
    "    similar_books = books_df[books_df['book_id'].isin(similar_book_ids)]\n",
    "    \n",
    "    # Add similarity scores and sort by score\n",
    "    similar_books_with_scores = similar_books.copy()\n",
    "    similar_books_with_scores['similarity'] = 0.0\n",
    "    \n",
    "    for i, book_id in enumerate(similar_book_ids):\n",
    "        idx = similar_books_with_scores.index[similar_books_with_scores['book_id'] == book_id]\n",
    "        if len(idx) > 0:\n",
    "            similar_books_with_scores.loc[idx[0], 'similarity'] = float(similarity_scores[i])\n",
    "    \n",
    "    # Sort by similarity\n",
    "    similar_books_with_scores = similar_books_with_scores.sort_values('similarity', ascending=False)\n",
    "    \n",
    "    return similar_books_with_scores\n",
    "\n",
    "\n",
    "\n",
    "def get_popular_books(books_df, n=10):\n",
    "    \"\"\"\n",
    "    Get the most popular books based on number of ratings.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    books_df : pandas DataFrame\n",
    "        DataFrame containing book information\n",
    "    n : int\n",
    "        Number of books to return\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with popular books\n",
    "    \"\"\"\n",
    "    # Sort by ratings count and get top N\n",
    "    popular_books = books_df.sort_values('ratings_count', ascending=False).head(n)\n",
    "    return popular_books\n",
    "\n",
    "\n",
    "def get_highly_rated_books(books_df, min_ratings=50, n=10):\n",
    "    \"\"\"\n",
    "    Get highly rated books (with a minimum number of ratings).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    books_df : pandas DataFrame\n",
    "        DataFrame containing book information\n",
    "    min_ratings : int\n",
    "        Minimum number of ratings required to consider a book\n",
    "    n : int\n",
    "        Number of books to return\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with highly rated books\n",
    "    \"\"\"\n",
    "    # Filter books with minimum number of ratings\n",
    "    qualified_books = books_df[books_df['ratings_count'] >= min_ratings]\n",
    "    \n",
    "    # Sort by average rating and get top N\n",
    "    highly_rated = qualified_books.sort_values('average_rating', ascending=False).head(n)\n",
    "    return highly_rated\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Main function to get recommendations by book ID\n",
    "def get_recommendations_by_book_id(book_id, n=10):\n",
    "    \"\"\"\n",
    "    Get recommendations for a specific book ID.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    book_id : int or str\n",
    "        The book ID to get recommendations for\n",
    "    n : int\n",
    "        Number of recommendations to generate\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with recommended books\n",
    "    \"\"\"\n",
    "    # Convert book_id to integer if it's a string\n",
    "    if isinstance(book_id, str) and book_id.isdigit():\n",
    "        book_id = int(book_id)\n",
    "    \n",
    "    try:\n",
    "        # Find the book in the dataset\n",
    "        book_info = books[books['book_id'] == book_id]\n",
    "        \n",
    "        if book_info.empty:\n",
    "            print(f\"Book ID {book_id} not found in the dataset\")\n",
    "            return None\n",
    "        \n",
    "        # Get book details\n",
    "        book_title = book_info['title'].iloc[0]\n",
    "        book_author = book_info['authors'].iloc[0]\n",
    "        \n",
    "        print(f\"Finding recommendations for: '{book_title}' by {book_author} (ID: {book_id})\")\n",
    "        \n",
    "        # Get similar books\n",
    "        similar_books = get_similar_books(\n",
    "            model,\n",
    "            book_id,\n",
    "            item_features,\n",
    "            dataset,\n",
    "            books,\n",
    "            n=n\n",
    "        )\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"\\nTop {n} recommendations based on '{book_title}':\")\n",
    "        result = similar_books[['book_id', 'title', 'authors', 'average_rating', 'similarity']]\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting recommendations: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Simple function to demonstrate usage\n",
    "def recommend_books(book_id, num_recommendations=10):\n",
    "    \"\"\"\n",
    "    Simple interface to get book recommendations.\n",
    "    Just provide a book ID and get recommendations.\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    recommendations = recommend_books(12)\n",
    "    print(recommendations)\n",
    "    \"\"\"\n",
    "    return get_recommendations_by_book_id(book_id, n=num_recommendations)\n",
    "\n",
    "# Example:\n",
    "# If you type: recommend_books(12)\n",
    "# You'll get recommendations similar to book ID 12\n",
    "\n",
    "\n",
    "# Main recommendation function for demonstration\n",
    "def generate_book_recommendations():\n",
    "    \"\"\"\n",
    "    Main function to demonstrate various recommendation approaches\n",
    "    \"\"\"\n",
    "    # Pick a popular book for demonstration\n",
    "    # Using book ID 1 as an example\n",
    "    sample_book_id = 1\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"BOOK RECOMMENDATION SYSTEM - RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Get recommendations for sample book\n",
    "    print(f\"\\nRECOMMENDATIONS FOR BOOK ID {sample_book_id}\")\n",
    "    recommendations = recommend_books(sample_book_id, 10)\n",
    "    if recommendations is not None:\n",
    "        print(recommendations)\n",
    "    \n",
    "    print(\"\\nTo get recommendations for any book, use:\")\n",
    "    print(\"recommend_books(book_id, num_recommendations=10)\")\n",
    "    print(\"\\nFor example: recommend_books(12) will give recommendations similar to book ID 12\")\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Uncomment to run the recommendation showcase\n",
    "# results = generate_book_recommendations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b41b3de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total items in model: 2000\n",
      "Total items in mapping: 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total items in model: {model.item_embeddings.shape[0]}\")\n",
    "print(f\"Total items in mapping: {len(item_id_map)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c01e911e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding recommendations for: 'The Hunger Games (The Hunger Games, #1)' by Suzanne Collins (ID: 1)\n",
      "Error getting recommendations: index 5694 is out of bounds for axis 0 with size 2000\n",
      "None\n",
      "Finding recommendations for: 'The Hunger Games (The Hunger Games, #1)' by Suzanne Collins (ID: 1)\n",
      "Error getting recommendations: index 5694 is out of bounds for axis 0 with size 2000\n"
     ]
    }
   ],
   "source": [
    "# Get recommendations for book ID 12\n",
    "recommendations = recommend_books(1)\n",
    "print(recommendations)\n",
    "\n",
    "# You can also specify the number of recommendations\n",
    "recommendations = recommend_books(1, num_recommendations=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b7c58a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Save the model for future use\\nimport pickle\\n\\n# Create a directory for models if it doesn\\'t exist\\nos.makedirs(\\'../models\\', exist_ok=True)\\n\\n# Save the model\\nwith open(\\'../models/lightfm_hybrid_model.pkl\\', \\'wb\\') as f:\\n    pickle.dump(model, f)\\n\\n# Save the dataset for mapping\\nwith open(\\'../models/lightfm_dataset.pkl\\', \\'wb\\') as f:\\n    pickle.dump(dataset, f)\\n\\n# Save the item features\\nwith open(\\'../models/lightfm_item_features.pkl\\', \\'wb\\') as f:\\n    pickle.dump(item_features, f)\\n\\nprint(\"Model and associated data saved successfully!\")'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Save the model for future use\n",
    "import pickle\n",
    "\n",
    "# Create a directory for models if it doesn't exist\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "with open('../models/lightfm_hybrid_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Save the dataset for mapping\n",
    "with open('../models/lightfm_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump(dataset, f)\n",
    "\n",
    "# Save the item features\n",
    "with open('../models/lightfm_item_features.pkl', 'wb') as f:\n",
    "    pickle.dump(item_features, f)\n",
    "\n",
    "print(\"Model and associated data saved successfully!\")'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
